# -*- coding: utf-8 -*-
"""field-delineation-end2end.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11yuLRlLVFMGFAbbraFaD_uPNrQ2JFq3G

# Field delineation

<div class="alert alert-block alert-info"><b>This notebooks includes the training and  prediction using  a neural network. 
    If running over a smaller area a CPU-only machine can be used, however if running on larger areas, we recommend using a machine with a GPU setup to speed up the processing time for those steps.  </b>

To run this  notebook out of the box, access to an Amazon AWS S3 bucket is required. Furthermore, the download of the satellite imagery is done through [Sentinel Hub](https://www.sentinel-hub.com/). To run locally (or with existing data) some modifications of the code might be required. 

The following data is a prerequisite for running this notebook:
  - **The georeferenced file with the area of interest** 
  - **Field boundary ground-truth data is required for training**
"""

# Commented out IPython magic to ensure Python compatibility.

import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = BASE_DIR + "/"
os.chdir(PROJECT_ROOT)


# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %load_ext autoreload
# %autoreload 2

import logging
import json
import numpy as np
import geopandas as gpd
import matplotlib.pyplot as plt
import pandas as pd

from eolearn.core import EOPatch
from sentinelhub import SHConfig
from shapely.geometry import Polygon

from fs.copy import copy_file
from fd.scripts.download import batch_download
from fd.scripts.tiffs_to_eopatches import convert_tiff_to_eopatches
from fd.scripts.vector_to_raster import rasterise_gsaa
from fd.scripts.sampling import sample_patchlets
from fd.scripts.patchlets_to_npz import patchlets_to_npz_files
from fd.scripts.normalization import calculate_normalization_factors
from fd.scripts.k_folds_split import k_fold_split
from fd.scripts.train import train_k_folds
from fd.scripts.predict import run_prediction
from fd.scripts.postprocessing import run_post_processing
from fd.scripts.vectorization import vectorise
from fd.scripts.utm_zone_merging import merge_zones

from fd.utils import BaseConfig, prepare_filesystem
from fd.utils_plot import (
    draw_vector_timeless,
    draw_true_color,
    draw_bbox,
    draw_mask,
    get_extent,
)

logging.getLogger().setLevel(logging.ERROR)

"""# Setup credentials

The procedure assumes access to a AWS S3 bucket from which it loads and stores data.
"""

BUCKET_NAME = ""
AWS_ACCESS_KEY_ID=''
AWS_SECRET_ACCESS_KEY=''
AWS_REGION = "eu-central-1"
SH_INSTANCE_ID = ""
SH_CLIENT_ID = ""
SH_CLIENT_SECRET = ""

sh_config = SHConfig()

sh_config.sh_client_id = SH_CLIENT_ID
sh_config.sh_client_secret = SH_CLIENT_SECRET
sh_config.aws_secret_access_key = AWS_SECRET_ACCESS_KEY
sh_config.aws_access_key_id = AWS_ACCESS_KEY_ID
sh_config.instance_id = SH_INSTANCE_ID

sh_config.save()

base_config = BaseConfig(
    bucket_name=BUCKET_NAME,
    aws_region=AWS_REGION,
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
)
filesystem = prepare_filesystem(base_config)


PROJECT_DATA_ROOT = (
    PROJECT_ROOT + "input-data/Slovenia/AOI/"
)  # !! Local folder where project related  files are/will be stored !!

INPUT_AOI_FILEPATH = os.path.join(PROJECT_DATA_ROOT, 'KMRS_extent.geojson') 
GRID_PATH = os.path.join(PROJECT_DATA_ROOT, 'KMRS_grid.gpkg')

TIME_INTERVAL = [
    "2019-03-01",
    "2019-09-30",
]  # Set the time interval for which the data will be downloaded

"""Folder configs """

BATCH_TIFFS_FOLDER = (
    "tiff-images"  # Location on the bucket where downloaded TIFF images will be stored
)

"""# Convert to EOPatches

**Define folder where EOPatches will be stored.**
"""

EOPATCHES_FOLDER = (
    "eopatches"  # Location on the bucket to which EOPatches will be saved.
)

tiffs_to_eop_config = {
    "bucket_name": BUCKET_NAME,
    "aws_access_key_id": AWS_ACCESS_KEY_ID,
    "aws_secret_access_key": AWS_SECRET_ACCESS_KEY,
    "aws_region": AWS_REGION,
    "grid_filename": GRID_PATH,
    "tiffs_folder": BATCH_TIFFS_FOLDER,
    "eopatches_folder": EOPATCHES_FOLDER,
    "band_names": ["B02", "B03", "B04", "B08"],
    "mask_name": "dataMask",
    "data_name": "BANDS",
    "is_data_mask": "IS_DATA",
    "clp_name": "CLP",
    "clm_name": "CLM",
    "max_workers": 6,
}

print("---#2-------Convert to EOPatches-------------")

convert_tiff_to_eopatches(tiffs_to_eop_config)

"""Check if EOPatches have been written"""

eops = filesystem.listdir(EOPATCHES_FOLDER)

print(eops)

"""Load a sample EOPatch to check the values """

eop = EOPatch.load(os.path.join(EOPATCHES_FOLDER, eops[0]), filesystem=filesystem)

print(eop)

tidx = 3  # select one timestamp between 0 and number of timestamps in the EOPatch
viz_factor = 2.5

fig, axs = plt.subplots(figsize=(15, 5), ncols=3, sharey=True)
axs[0].imshow(viz_factor * eop.data["BANDS"][tidx][..., [2, 1, 0]] / 10000)
axs[0].set_title("RGB bands")
axs[1].imshow(eop.data["CLP"][tidx].squeeze() / 255, vmin=0, vmax=1)
axs[1].set_title("Cloud probability")
axs[2].imshow(eop.mask["IS_DATA"][tidx].squeeze(), vmin=0, vmax=1)
axs[2].set_title("Valid data")
plt.show()
